<!doctype html>
<html lang="hi">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>üîÆ AstroOne Live ‚Äî Talk with Sumit Aggarwal</title>
<style>
  body{margin:0;font-family:Poppins,Arial,Helvetica,sans-serif;background:linear-gradient(135deg,#6a11cb,#2575fc);height:100vh;display:flex;align-items:center;justify-content:center}
  .card{width:430px;background:#fff;border-radius:16px;padding:22px 24px;box-shadow:0 12px 30px rgba(0,0,0,0.18);text-align:center}
  h2{margin:0 0 12px;font-size:20px;color:#222}
  input,select{width:100%;padding:10px;margin:8px 0;border-radius:8px;border:1px solid #ddd;font-size:15px}
  button{width:100%;padding:12px;border-radius:8px;border:0;font-weight:600;cursor:pointer;margin-top:8px}
  #connect{background:#6a11cb;color:#fff} #disconnect{background:#e74c3c;color:#fff;display:none}
  #status{margin-top:12px;color:#333;min-height:20px}
  .footer{margin-top:10px;color:#888;font-size:12px}
</style>
</head>
<body>
  <div class="card">
    <h2>üîÆ AstroOne Live ‚Äî Talk with Sumit Aggarwal</h2>

    <input id="name" placeholder="‡§™‡•Ç‡§∞‡§æ ‡§®‡§æ‡§Æ">
    <input id="dob" type="date">
    <input id="tob" type="time">
    <input id="pob" placeholder="‡§ú‡§®‡•ç‡§Æ ‡§∏‡•ç‡§•‡§æ‡§® (‡§∂‡§π‡§∞)">
    <select id="gender"><option value="">‡§≤‡§ø‡§Ç‡§ó ‡§ö‡•Å‡§®‡•á</option><option value="male">‡§™‡•Å‡§∞‡•Å‡§∑</option><option value="female">‡§Æ‡§π‡§ø‡§≤‡§æ</option><option value="other">‡§Ö‡§®‡•ç‡§Ø</option></select>

    <select id="voice">
      <option value="verse">Verse</option>
      <option value="alloy">Alloy</option>
      <option value="ash">Ash</option>
      <option value="ballad">Ballad</option>
      <option value="coral">Coral</option>
      <option value="echo">Echo</option>
      <option value="sage">Sage</option>
      <option value="shimmer">Shimmer</option>
      <option value="marin">Marin</option>
      <option value="cedar">Cedar</option>
    </select>

    <button id="connect">‚ñ∂Ô∏è Start Live Call</button>
    <button id="disconnect">‚èπ End Call</button>

    <div id="status">‡§Ö‡§™‡§®‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§≠‡§∞‡•á‡§Ç ‡§î‡§∞ Start ‡§¶‡§¨‡§æ‡§è‡§Å‡•§</div>
    <audio id="audioPlayer" autoplay playsinline></audio>
    <div class="footer">AstroOne Realtime ¬© 2025</div>
  </div>

<script>
/*
client/index_ws.html
- connects to server WS at /ws on same origin
- sends {type:"init", name, dob, tob, pob, gender, voice}
- captures mic after ws.onopen
- sends {type:"media", data: base64_pcm16}
- every N ms sends {type:"media_commit"} to trigger model response
- plays back output_audio_binary frames (base64)
*/

const connectBtn = document.getElementById("connect");
const disconnectBtn = document.getElementById("disconnect");
const statusEl = document.getElementById("status");
const audioPlayer = document.getElementById("audioPlayer");

let ws = null;
let mediaStream = null;
let audioCtx = null;
let processor = null;
let sourceNode = null;
let commitTimer = null;

function setStatus(s){ statusEl.innerText = s; console.log(s); }

// convert Float32Array -> 16-bit PCM -> base64
function floatToBase64(float32Array){
  const len = float32Array.length;
  const buffer = new ArrayBuffer(len * 2);
  const view = new DataView(buffer);
  for (let i=0;i<len;i++){
    let s = Math.max(-1, Math.min(1, float32Array[i]));
    view.setInt16(i*2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
  }
  let binary = "";
  const bytes = new Uint8Array(buffer);
  const chunk = 0x8000;
  for (let i=0;i<bytes.length;i+=chunk){
    binary += String.fromCharCode.apply(null, bytes.subarray(i, i+chunk));
  }
  return btoa(binary);
}

// play base64 (expects encoded audio in a codec the server/OpenAI returned, typically raw wav/ogg depending on model)
function playBase64Audio(b64){
  try {
    const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));
    audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
    audioCtx.decodeAudioData(bytes.buffer, buffer => {
      const src = audioCtx.createBufferSource();
      src.buffer = buffer;
      src.connect(audioCtx.destination);
      src.start();
    }, err => { console.warn("decodeAudioData err", err); });
  } catch(e){
    console.warn("playBase64Audio error", e);
  }
}

// start call
async function startCall(){
  const name = document.getElementById("name").value.trim();
  const dob = document.getElementById("dob").value;
  const tob = document.getElementById("tob").value;
  const pob = document.getElementById("pob").value.trim();
  const gender = document.getElementById("gender").value;
  const voice = document.getElementById("voice").value;

  if(!name || !dob || !tob || !pob || !gender){
    setStatus("‚ö†Ô∏è ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§≠‡•Ä ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§≠‡§∞‡•á‡§Ç‡•§");
    return;
  }

  const wsUrl = (location.protocol === "https:" ? "wss://" : "ws://") + location.host + "/ws";
  ws = new WebSocket(wsUrl);
  setStatus("üõ∞ Connecting to server...");

  ws.onopen = async () => {
    setStatus("üîÆ Connected. Sending init...");
    // send init (server will create OpenAI session and inject kundli)
    ws.send(JSON.stringify({ type: "init", name, dob, tob, pob, gender, voice }));

    // wait a little to let server connect to OpenAI
    await new Promise(resolve => setTimeout(resolve, 700));

    // start mic capture
    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } catch (e) {
      setStatus("üîá Microphone access denied.");
      console.error(e);
      return;
    }

    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    sourceNode = audioCtx.createMediaStreamSource(mediaStream);
    processor = audioCtx.createScriptProcessor(4096, 1, 1);
    sourceNode.connect(processor);
    processor.connect(audioCtx.destination);

    processor.onaudioprocess = (e) => {
      if (!ws || ws.readyState !== WebSocket.OPEN) return;
      const float32 = e.inputBuffer.getChannelData(0);
      const b64 = floatToBase64(float32);
      // send audio chunk
      ws.send(JSON.stringify({ type: "media", data: b64 }));
    };

    // commit every 4 seconds to get model response
    commitTimer = setInterval(() => {
      if (ws && ws.readyState === WebSocket.OPEN) ws.send(JSON.stringify({ type: "media_commit" }));
    }, 2000);

    connectBtn.style.display = "none";
    disconnectBtn.style.display = "block";
    setStatus("üéô Live call started ‚Äî ‡§¨‡•ã‡§≤‡§ø‡§è...");
  };

  ws.onmessage = (evt) => {
    try {
      const data = JSON.parse(evt.data);
      // We forward output_audio_binary (base64) from server as 'output_audio_binary'
      if (data?.type === "output_audio_binary" && data?.data) {
        playBase64Audio(data.data);
      } else if (data?.type === "output_audio_buffer.append" && data?.audio) {
        // some server versions forward as 'audio' field
        playBase64Audio(data.audio);
      } else {
        // handle other events as debug
        console.log("svr>", data);
      }
    } catch(e){
      console.warn("ws message parse error", e);
    }
  };

  ws.onerror = (err) => {
    console.error("WebSocket error", err);
    setStatus("‚ùå Connection error.");
    stopCall();
  };

  ws.onclose = () => {
    setStatus("üì¥ Call ended");
    stopCall();
  };
}

function stopCall(){
  if (commitTimer) { clearInterval(commitTimer); commitTimer = null; }
  try { if (processor) { processor.disconnect(); processor = null; } } catch(e){}
  try { if (sourceNode) { sourceNode.disconnect(); sourceNode = null; } } catch(e){}
  if (mediaStream) { mediaStream.getTracks().forEach(t=>t.stop()); mediaStream = null; }
  try { if (ws && ws.readyState === WebSocket.OPEN) ws.send(JSON.stringify({ type: "stop" })); } catch(e){}
  try { if (ws) ws.close(); } catch(e){}
  ws = null;
  connectBtn.style.display = "block";
  disconnectBtn.style.display = "none";
  setStatus("üì¥ Call stopped.");
}

connectBtn.addEventListener("click", startCall);
disconnectBtn.addEventListener("click", stopCall);
</script>
</body>
</html>
